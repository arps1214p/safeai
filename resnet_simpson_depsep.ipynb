{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arps1214p/safeai/blob/main/resnet_simpson_depsep.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cbc77b43",
      "metadata": {
        "id": "cbc77b43"
      },
      "source": [
        "# 라이브러리 Import 및 환경 설정"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install addict\n",
        "\n",
        "#!mkdir /kaggle/working"
      ],
      "metadata": {
        "id": "TXdCmlNyzl1x"
      },
      "id": "TXdCmlNyzl1x",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b1eedcc1",
      "metadata": {
        "id": "b1eedcc1"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.backends import cudnn\n",
        "\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torchvision import datasets, models, transforms\n",
        "\n",
        "import PIL\n",
        "from PIL import Image\n",
        "\n",
        "import math\n",
        "import random\n",
        "import seaborn as sn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from skimage import io\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "from tqdm import tqdm_notebook\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Ignore warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import argparse, yaml\n",
        "from addict import Dict\n",
        "\n",
        "import kagglehub\n",
        "\n",
        "\n",
        "print(\"PyTorch Version: \", torch.__version__)\n",
        "print(\"Torchvision Version: \", torchvision.__version__)\n",
        "print(\"Pillow Version: \", PIL.__version__)\n",
        "\n",
        "train_on_gpu = torch.cuda.is_available()\n",
        "\n",
        "if not train_on_gpu:\n",
        "    print('CUDA is not available.  Training on CPU ...')\n",
        "else:\n",
        "    print('CUDA is available!  Training on GPU ...')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a10bb5c9",
      "metadata": {
        "id": "a10bb5c9"
      },
      "source": [
        "### config 변수 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "78eca193",
      "metadata": {
        "id": "78eca193"
      },
      "outputs": [],
      "source": [
        "#config 불러오기\n",
        "def get_cfg():\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument(\"--config\", type=str, default=\"config.yaml\")\n",
        "    args, _ = parser.parse_known_args()\n",
        "\n",
        "    # args.config 에 지정된 YAML 파일 읽어서 Dict 형태로 반환\n",
        "    with open(args.config) as f:\n",
        "        cfg = Dict(yaml.safe_load(f))\n",
        "    return cfg\n",
        "\n",
        "cfg = get_cfg()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d176c781",
      "metadata": {
        "id": "d176c781"
      },
      "outputs": [],
      "source": [
        "#전역 시드 고정\n",
        "\n",
        "def set_global_seed(seed):\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    cudnn.deterministic = True\n",
        "    cudnn.benchmark = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64ae17bb",
      "metadata": {
        "id": "64ae17bb"
      },
      "outputs": [],
      "source": [
        "set_global_seed(cfg.seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "77f4dd60",
      "metadata": {
        "id": "77f4dd60"
      },
      "source": [
        "### config 변수 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a2e1453",
      "metadata": {
        "id": "7a2e1453"
      },
      "outputs": [],
      "source": [
        "# random seed\n",
        "seed            = cfg.seed\n",
        "# train_split ratio\n",
        "train_split     = cfg.data.train_split\n",
        "# train_split random seed\n",
        "random_state    = cfg.data.random_state\n",
        "batch_size      = cfg.data.batch_size\n",
        "num_workers     = cfg.data.num_workers\n",
        "input_size      = cfg.data.input_size\n",
        "\n",
        "model_name      = cfg.model.name\n",
        "pretrained      = cfg.model.pretrained\n",
        "# feature_extract = False - 전체 모델 학습\n",
        "# feature_extract = True - Fc 레이어만 학습\n",
        "feature_extract = cfg.model.feature_extract\n",
        "\n",
        "optimizer_name  = cfg.training.optimizer\n",
        "lr              = cfg.training.lr\n",
        "momentum        = cfg.training.momentum\n",
        "weight_decay    = cfg.training.weight_decay\n",
        "scheduler_type  = cfg.training.scheduler\n",
        "step_size       = cfg.training.step_size\n",
        "gamma           = cfg.training.gamma\n",
        "num_epochs      = cfg.training.epochs\n",
        "\n",
        "random_flip     = cfg.augmentation.random_flip\n",
        "color_jitter    = cfg.augmentation.color_jitter\n",
        "cutmix          = cfg.augmentation.cutmix"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "01526ff4",
      "metadata": {
        "id": "01526ff4"
      },
      "source": [
        "# 데이터 가져오기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "13f02f2c",
      "metadata": {
        "id": "13f02f2c"
      },
      "outputs": [],
      "source": [
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"alexattia/the-simpsons-characters-dataset\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb1b15a4",
      "metadata": {
        "id": "cb1b15a4"
      },
      "outputs": [],
      "source": [
        "# the-simpsons-characters-dataset/simpsons_dataset 디렉토리(-> 큰 폴더) 밑에 simpsons_dataset 디렉토리(->작은 폴더)가 하나 더 있는데,\n",
        "# 작은 폴더에 들어있는 이미지가 큰 폴더에 들어있는 이미지와 완전히 같아서 중복을 제거하기 위해 작은 폴더를 train_dir로 설정했어요\n",
        "train_dir = Path('/kaggle/input/the-simpsons-characters-dataset/simpsons_dataset/simpsons_dataset')\n",
        "test_dir = Path('/kaggle/input/the-simpsons-characters-dataset/kaggle_simpson_testset/kaggle_simpson_testset')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "20df52ad",
      "metadata": {
        "id": "20df52ad"
      },
      "outputs": [],
      "source": [
        "class TrainValTestSplit():\n",
        "\n",
        "  def __init__(self, train_dir, test_dir):\n",
        "\n",
        "    self.train_dir = train_dir\n",
        "    self.test_dir = test_dir\n",
        "    # 하위 디렉토리를 순회하며 이미지의 경로를 리스트로 저장\n",
        "    self.train_val_files_path = sorted(list(self.train_dir.rglob('*.jpg')))\n",
        "    self.test_path = sorted(list(self.test_dir.rglob('*.jpg')))\n",
        "    self.train_val_labels = [path.parent.name for path in self.train_val_files_path]\n",
        "\n",
        "  def get_path(self):\n",
        "\n",
        "    train_files_path, val_files_path = train_test_split(self.train_val_files_path, test_size = 0.3, \\\n",
        "                                          stratify=self.train_val_labels, random_state = 42)\n",
        "\n",
        "    train_val_files_path = {'train': train_files_path, 'val': val_files_path}\n",
        "\n",
        "    return train_val_files_path, self.test_path\n",
        "\n",
        "  def get_n_classes(self):\n",
        "    return len(np.unique(self.train_val_labels))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4858a087",
      "metadata": {
        "id": "4858a087"
      },
      "outputs": [],
      "source": [
        "TrainValTestPath = TrainValTestSplit(train_dir, test_dir)\n",
        "train_path, test_path = TrainValTestPath.get_path()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d3f0e02b",
      "metadata": {
        "id": "d3f0e02b"
      },
      "source": [
        "## 모델 학습 함수"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 조기종료 함수\n",
        "https://github.com/Bjarten/early-stopping-pytorch/blob/main/early_stopping_pytorch/early_stopping.py\n"
      ],
      "metadata": {
        "id": "gT4grHBe1cbT"
      },
      "id": "gT4grHBe1cbT"
    },
    {
      "cell_type": "code",
      "source": [
        "# 조기종료 함수\n",
        "class EarlyStopping:\n",
        "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
        "    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt', trace_func=print):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            patience (int): How long to wait after last time validation loss improved.\n",
        "                            Default: 7\n",
        "            verbose (bool): If True, prints a message for each validation loss improvement.\n",
        "                            Default: False\n",
        "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
        "                            Default: 0\n",
        "            path (str): Path for the checkpoint to be saved to.\n",
        "                            Default: 'checkpoint.pt'\n",
        "            trace_func (function): trace print function.\n",
        "                            Default: print\n",
        "        \"\"\"\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.counter = 0\n",
        "        self.best_val_loss = None\n",
        "        self.early_stop = False\n",
        "        self.val_loss_min = np.inf\n",
        "        self.delta = delta\n",
        "        self.path = path\n",
        "        self.trace_func = trace_func\n",
        "\n",
        "    def __call__(self, val_loss, model):\n",
        "        # Check if validation loss is nan\n",
        "        if np.isnan(val_loss):\n",
        "            self.trace_func(\"Validation loss is NaN. Ignoring this epoch.\")\n",
        "            return\n",
        "\n",
        "        if self.best_val_loss is None:\n",
        "            self.best_val_loss = val_loss\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "        elif val_loss < self.best_val_loss - self.delta:\n",
        "            # Significant improvement detected\n",
        "            self.best_val_loss = val_loss\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "            self.counter = 0  # Reset counter since improvement occurred\n",
        "        else:\n",
        "            # No significant improvement\n",
        "            self.counter += 1\n",
        "            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "\n",
        "    def save_checkpoint(self, val_loss, model):\n",
        "        '''Saves model when validation loss decreases.'''\n",
        "        if self.verbose:\n",
        "            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
        "        torch.save(model.state_dict(), self.path)\n",
        "        self.val_loss_min = val_loss"
      ],
      "metadata": {
        "id": "Q8XMPSXS1bpE"
      },
      "id": "Q8XMPSXS1bpE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d5574991",
      "metadata": {
        "id": "d5574991"
      },
      "outputs": [],
      "source": [
        "def train_model(model, dataloaders, criterion, optimizer, save_best_weights_path, save_last_weights_path, num_epochs=cfg.training.epochs, is_inception=False, early_stopping=None):\n",
        "    since = time.time()\n",
        "\n",
        "    val_acc_history = []\n",
        "    val_loss_history = []\n",
        "    train_acc_history = []\n",
        "    train_loss_history = []\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # train과 val 단계에 따라 model 모드 변경\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()\n",
        "            else:\n",
        "                model.eval()\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            for inputs, labels in tqdm_notebook(dataloaders[phase]):\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # train 모드라면 hitstory 저장\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    # inception module을 사용하는 모델인경우 loss 설정\n",
        "                    if is_inception and phase == 'train':\n",
        "                        outputs, aux_outputs = model(inputs)\n",
        "                        loss1 = criterion(outputs, labels)\n",
        "                        loss2 = criterion(aux_outputs, labels)\n",
        "                        loss = loss1 + 0.4*loss2\n",
        "                    else:\n",
        "                        outputs = model(inputs)\n",
        "                        loss = criterion(outputs, labels)\n",
        "\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "\n",
        "                    # backward + optimizer train mode\n",
        "                    # scheduler의 경우 일단 비활성화\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "                        #scheduler.step()\n",
        "                        #lr_step = optimizer_ft.state_dict()[\"param_groups\"][0][\"lr\"]\n",
        "                        #lr_find_lr.append(lr_step)\n",
        "\n",
        "                # 현재 에포크의 손실 저장\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels)\n",
        "\n",
        "            # loss, acc 계산\n",
        "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
        "            epoch_acc = running_corrects.float() / len(dataloaders[phase].dataset)\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            # 현재 epoch의 정확도가 best_acc 보다 큰 경우 best 모델을 변경\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "                # best model 저장장\n",
        "                torch.save(best_model_wts, save_best_weights_path)\n",
        "            # 현재 epoch의 정확도를 history에 저장\n",
        "            if phase == 'val':\n",
        "                val_acc_history.append(epoch_acc.item())\n",
        "                val_loss_history.append(epoch_loss)\n",
        "            else:\n",
        "                train_acc_history.append(epoch_acc.item())\n",
        "                train_loss_history.append(epoch_loss)\n",
        "\n",
        "        torch.save(model.state_dict(), save_last_weights_path)\n",
        "        print()\n",
        "        # epoch를 수행한 뒤 early stopping 조건 확인\n",
        "        if early_stopping is not None:\n",
        "            early_stopping(val_loss_history[-1], model)\n",
        "            if early_stopping.early_stop: # 조건 만족 시 조기 종료\n",
        "                break\n",
        "\n",
        "    # 학습시간 계산\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # best model 로드\n",
        "    model.load_state_dict(best_model_wts)\n",
        "\n",
        "    history_val = {'loss': val_loss_history, 'acc': val_acc_history}\n",
        "    history_train = {'loss': train_loss_history, 'acc': train_acc_history}\n",
        "\n",
        "    return model, history_val, history_train, time_elapsed, best_acc"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "373cb8c7",
      "metadata": {
        "id": "373cb8c7"
      },
      "source": [
        "## transfer learning 시 동작 결정 함수"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f7b5cf5f",
      "metadata": {
        "id": "f7b5cf5f"
      },
      "outputs": [],
      "source": [
        "# feature_extracting이 설정된 경우 fc레이어의 param만 학습\n",
        "def set_parameter_requires_grad(model, feature_extracting):\n",
        "    if feature_extracting:\n",
        "        for param in model.parameters():\n",
        "            param.requires_grad = False"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2bbacbef",
      "metadata": {
        "id": "2bbacbef"
      },
      "source": [
        "## torch.models로부터 모델을 불러오는 함수"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "269ad56e",
      "metadata": {
        "id": "269ad56e"
      },
      "outputs": [],
      "source": [
        "def initialize_model(model_name, num_classes, feature_extract, use_pretrained):\n",
        "\n",
        "    model_ft = None\n",
        "\n",
        "    if model_name == \"resnet152\":\n",
        "        \"\"\" Resnet152\n",
        "        \"\"\"\n",
        "        model_ft = models.resnet152(pretrained=use_pretrained)\n",
        "        # feature_extract=true인 경우 마지막 fc레이어의 param만 학습\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        num_ftrs = model_ft.fc.in_features\n",
        "        # fc레이어의 output 개수 설정\n",
        "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
        "\n",
        "    elif model_name == \"resnet18\":\n",
        "        \"\"\" Resnet18\n",
        "        \"\"\"\n",
        "        model_ft = models.resnet18(pretrained=use_pretrained)\n",
        "        # feature_extract=true인 경우 마지막 fc레이어의 param만 학습\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        num_ftrs = model_ft.fc.in_features\n",
        "        # fc레이어의 output 개수 설정\n",
        "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
        "\n",
        "    else:\n",
        "        print(\"Invalid model name, exiting...\")\n",
        "        exit()\n",
        "\n",
        "    return model_ft"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "484b6b4a",
      "metadata": {
        "id": "484b6b4a"
      },
      "source": [
        "## 데이터셋 클래스"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "abce1982",
      "metadata": {
        "id": "abce1982"
      },
      "outputs": [],
      "source": [
        "class SimpsonsDataset(Dataset):\n",
        "\n",
        "    def __init__(self, files_path, data_transforms):\n",
        "      self.files_path = files_path\n",
        "      self.transform = data_transforms\n",
        "\n",
        "      if 'test' not in str(self.files_path[0]):\n",
        "        self.labels = [path.parent.name for path in self.files_path]\n",
        "        self.label_encoder = LabelEncoder()\n",
        "        self.label_encoder.fit(self.labels)\n",
        "\n",
        "        with open('label_encoder.pkl', 'wb') as le_dump_file:\n",
        "            pickle.dump(self.label_encoder, le_dump_file)\n",
        "\n",
        "    def __len__(self):\n",
        "      return len(self.files_path)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "      img_path = str(self.files_path[idx])\n",
        "      image = Image.open(img_path)\n",
        "      image = self.transform(image)\n",
        "\n",
        "      if 'test' in str(self.files_path[0]):\n",
        "        return image\n",
        "      else:\n",
        "        label_str = str(self.files_path[idx].parent.name)\n",
        "        label = self.label_encoder.transform([label_str]).item()\n",
        "\n",
        "        return image, label"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8d865b48",
      "metadata": {
        "id": "8d865b48"
      },
      "source": [
        "# 모델 설정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe0a6473",
      "metadata": {
        "id": "fe0a6473"
      },
      "outputs": [],
      "source": [
        "#fc_layer = 'all-st-SGD-m.9-nest-s-cycle-exp-.00001-.05-g.99994-m.8-.9'\n",
        "\n",
        "# device 설정\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# 가중치 저장\n",
        "save_last_weights_path = '/kaggle/working/' + model_name + '-' + '_last_weights.pth'\n",
        "save_best_weights_path = '/kaggle/working/' + model_name + '-' + '_best_weights.pth'\n",
        "\n",
        "num_classes = TrainValTestPath.get_n_classes()\n",
        "\n",
        "model_ft = initialize_model(model_name, num_classes, feature_extract, pretrained)\n",
        "\n",
        "model_ft = model_ft.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0411a5eb",
      "metadata": {
        "id": "0411a5eb"
      },
      "source": [
        "# 데이터 Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c49a6f9",
      "metadata": {
        "id": "5c49a6f9"
      },
      "outputs": [],
      "source": [
        "# ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) -> imagenet 데이터셋의 통계 기반\n",
        "# TODO\n",
        "# simpson 데이터셋 전체의 std와 mean 계산 후 정규화에 이용\n",
        "\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.Resize((input_size,input_size)),\n",
        "        #transforms.CenterCrop(input_size),\n",
        "        transforms.RandomChoice( [\n",
        "                                  transforms.RandomHorizontalFlip(p=0.5),\n",
        "                                  transforms.ColorJitter(contrast=0.9),\n",
        "                                  transforms.ColorJitter(brightness=0.1),\n",
        "                                  transforms.RandomApply( [ transforms.RandomHorizontalFlip(p=1), transforms.ColorJitter(contrast=0.9) ], p=0.5),\n",
        "                                  transforms.RandomApply( [ transforms.RandomHorizontalFlip(p=1), transforms.ColorJitter(brightness=0.1) ], p=0.5),\n",
        "                                  ] ),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize((input_size,input_size)),\n",
        "        #transforms.CenterCrop(input_size),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eea1a007",
      "metadata": {
        "id": "eea1a007"
      },
      "source": [
        "# 모델에 전달될 데이터 설정"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8e795489",
      "metadata": {
        "id": "8e795489"
      },
      "source": [
        "### Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4815bbdb",
      "metadata": {
        "id": "4815bbdb"
      },
      "outputs": [],
      "source": [
        "image_datasets = {mode: SimpsonsDataset(train_path[mode], data_transforms[mode]) for mode in ['train', 'val']}\n",
        "image_datasets_test = SimpsonsDataset(test_path, data_transforms['val'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8eafd3ce",
      "metadata": {
        "id": "8eafd3ce"
      },
      "source": [
        "### Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d691a34",
      "metadata": {
        "id": "3d691a34"
      },
      "outputs": [],
      "source": [
        "def seed_worker(worker_id):\n",
        "    worker_seed = torch.initial_seed() % 2**32\n",
        "    np.random.seed(worker_seed)\n",
        "    random.seed(worker_seed)\n",
        "\n",
        "g = torch.Generator()\n",
        "g.manual_seed(0)\n",
        "\n",
        "dataloaders_dict = {'train': torch.utils.data.DataLoader(image_datasets['train'], batch_size=batch_size, shuffle=True,\n",
        "                                                         num_workers=num_workers, worker_init_fn=seed_worker,generator=g),\n",
        "                    'val': torch.utils.data.DataLoader(image_datasets['val'], batch_size=batch_size, shuffle=True,\n",
        "                                                       num_workers=num_workers,worker_init_fn=seed_worker,generator=g)}\n",
        "dataloader_test = torch.utils.data.DataLoader(image_datasets_test, batch_size=batch_size, shuffle=False,\n",
        "                                              num_workers=num_workers, worker_init_fn=seed_worker,generator=g)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0af8066c",
      "metadata": {
        "id": "0af8066c"
      },
      "source": [
        "### 샘플 출력"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d127297",
      "metadata": {
        "id": "4d127297"
      },
      "outputs": [],
      "source": [
        "def imshow(inp, title=None, plt_ax=plt, default=False):\n",
        "    inp = inp.numpy().transpose((1, 2, 0))\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    inp = std * inp + mean\n",
        "    inp = np.clip(inp, 0, 1)\n",
        "    plt_ax.imshow(inp)\n",
        "    if title is not None:\n",
        "        plt_ax.set_title(title)\n",
        "    plt_ax.grid(False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "adf2dd33",
      "metadata": {
        "id": "adf2dd33"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(nrows=3, ncols=3,figsize=(8, 8), \\\n",
        "                        sharey=True, sharex=True)\n",
        "for fig_x in ax.flatten():\n",
        "    random_characters = int(np.random.uniform(0, 4500))\n",
        "    im_val, label = image_datasets['train'][random_characters]\n",
        "    # 캐릭터 이름 출력\n",
        "    img_label = \" \".join(map(lambda x: x.capitalize(),\\\n",
        "                image_datasets['val'].label_encoder.inverse_transform([label])[0].split('_')))\n",
        "    imshow(im_val.data.cpu(), \\\n",
        "          title=img_label,plt_ax=fig_x)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "04ab5c79",
      "metadata": {
        "id": "04ab5c79"
      },
      "source": [
        "# 파라미터 설정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4dfe970c",
      "metadata": {
        "collapsed": true,
        "id": "4dfe970c"
      },
      "outputs": [],
      "source": [
        "params_to_update = model_ft.parameters()\n",
        "print(\"Params to learn:\")\n",
        "if feature_extract:\n",
        "    params_to_update = []\n",
        "    for name, param in model_ft.named_parameters():\n",
        "        if param.requires_grad == True:\n",
        "            params_to_update.append(param)\n",
        "            print(\"\\t\",name)\n",
        "else:\n",
        "    for name,param in model_ft.named_parameters():\n",
        "        if param.requires_grad == True:\n",
        "            pass\n",
        "            print(\"\\t\",name)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de8bccf9",
      "metadata": {
        "id": "de8bccf9"
      },
      "source": [
        "# 학습"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cfa84609",
      "metadata": {
        "id": "cfa84609"
      },
      "source": [
        "학습은\n",
        " lr_scheduler.CyclicLR를 이용해 최적의 lr 범위를 찾고\n",
        " 이를 이용하여 실제 학습하는 두 단계로 이루어짐"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "52f1ef2e",
      "metadata": {
        "id": "52f1ef2e"
      },
      "source": [
        "## 1. lr 범위 결정\n",
        "\n",
        "Оптимизацию lr будем проводить используя циклическое изменение его значений в указанном диапазоне. Вначале необходимо определить оптимальные границы диапазона. Для этого проведем тестовый запуск. Выберем step size таким образом, чтобы во время тестового запуска lr линейно возрастал. <br>\n",
        "\n",
        "После чего построим график accuracy относительно learning rate, на основании графика выберем диапазон значений.\n",
        "\n",
        "Метод: https://arxiv.org/pdf/1506.01186.pdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ef308ea",
      "metadata": {
        "id": "8ef308ea"
      },
      "outputs": [],
      "source": [
        "# base_lr = 0.00001\n",
        "# max_lr = 0.05\n",
        "# lr_find_epochs = 2\n",
        "\n",
        "# cost = nn.CrossEntropyLoss()\n",
        "\n",
        "# optimizer_ft = optim.SGD(params_to_update, lr=0.001, momentum=0.9, nesterov = True)\n",
        "\n",
        "# step_size = lr_find_epochs * len(dataloaders_dict['train'])\n",
        "\n",
        "# scheduler = optim.lr_scheduler.CyclicLR(optimizer_ft, base_lr = base_lr, max_lr = max_lr, step_size_up=step_size, mode='exp_range', gamma=0.99994, scale_mode='cycle', cycle_momentum=True, base_momentum=0.8, max_momentum=0.9, last_epoch=-1)\n",
        "\n",
        "# def search_lr(lr_find_epochs):\n",
        "\n",
        "#   accs = []\n",
        "#   lr_find_lr = []\n",
        "#   acc_sum = 0.0\n",
        "\n",
        "#   for i in range(lr_find_epochs):\n",
        "#     print(\"epoch {}\".format(i))\n",
        "#     for inputs, labels in tqdm_notebook(dataloaders_dict['train']):\n",
        "\n",
        "#       inputs = inputs.to(device)\n",
        "#       labels = labels.to(device)\n",
        "\n",
        "#       model_ft.train()\n",
        "#       optimizer_ft.zero_grad()\n",
        "\n",
        "#       outputs = model_ft(inputs)\n",
        "#       loss = cost(outputs, labels)\n",
        "#       preds = torch.argmax(outputs, 1)\n",
        "#       acc_running = torch.sum(preds == labels.data).item()\n",
        "#       acc_sum += torch.sum(preds == labels.data).item()\n",
        "\n",
        "#       loss.backward()\n",
        "#       optimizer_ft.step()\n",
        "#       scheduler.step()\n",
        "\n",
        "#       lr_step = optimizer_ft.state_dict()[\"param_groups\"][0][\"lr\"]\n",
        "#       lr_find_lr.append(lr_step)\n",
        "\n",
        "#       accs.append(acc_running)\n",
        "#   accs = np.array(accs) / acc_sum\n",
        "\n",
        "#   return lr_find_lr, accs\n",
        "\n",
        "# lr_find_lr, accs = search_lr(lr_find_epochs)\n",
        "\n",
        "# plt.figure(figsize=(20,10))\n",
        "# plt.plot(np.array(lr_find_lr), np.array(accs));"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "78f2baaa",
      "metadata": {
        "id": "78f2baaa"
      },
      "source": [
        "## 2. 모델 학습"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## depthwise separable conv 적용\n",
        "https://github.com/mshalimay/Tuning-PerformanceEvaluation-ResMobile-Pytorch/blob/master/Examples.md"
      ],
      "metadata": {
        "id": "MUaxsOV4hzQD"
      },
      "id": "MUaxsOV4hzQD"
    },
    {
      "cell_type": "code",
      "source": [
        "class DepthwiseSeparableConv(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, bias=False):\n",
        "        super(DepthwiseSeparableConv, self).__init__()\n",
        "        self.depthwise = nn.Conv2d(in_channels, in_channels, kernel_size=kernel_size, stride=stride, padding=padding, groups=in_channels, bias=bias)\n",
        "        self.pointwise = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0, bias=bias)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.depthwise(x)\n",
        "        x = self.pointwise(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "-ksgz_LUaCiO"
      },
      "id": "-ksgz_LUaCiO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모든 conv2d layer를 변경\n",
        "def replace_conv2d_with_dsconv(model):\n",
        "    for name, module in model.named_children():\n",
        "        if isinstance(module, nn.Conv2d):\n",
        "            # Replace Conv2d with DepthwiseSeparableConv\n",
        "            # Need to get the correct parameters from the original Conv2d layer\n",
        "            in_channels = module.in_channels\n",
        "            out_channels = module.out_channels\n",
        "            kernel_size = module.kernel_size\n",
        "            stride = module.stride\n",
        "            padding = module.padding\n",
        "            bias = module.bias is not None\n",
        "\n",
        "            new_conv = DepthwiseSeparableConv(in_channels, out_channels, kernel_size, stride, padding, bias=bias)\n",
        "\n",
        "            # Assuming the Conv2d layer is a direct child of the current module.\n",
        "            # This might need adjustment based on the specific model's architecture.\n",
        "            setattr(model, name, new_conv)\n",
        "        elif len(list(module.children())) > 0:\n",
        "            # Recursively apply the replacement to nested modules\n",
        "            replace_conv2d_with_dsconv(module)\n",
        "\n",
        "# 첫 레이어 제외\n",
        "def replace_conv2d_with_dsconv_except_first(model):\n",
        "    for name, module in model.named_children():\n",
        "        if isinstance(module, nn.Conv2d):\n",
        "            if module.kernel_size == (7,7):\n",
        "                continue\n",
        "\n",
        "            in_channels = module.in_channels\n",
        "            out_channels = module.out_channels\n",
        "            kernel_size = module.kernel_size\n",
        "            stride = module.stride\n",
        "            padding = module.padding\n",
        "            bias = module.bias is not None\n",
        "\n",
        "            new_conv = DepthwiseSeparableConv(in_channels, out_channels, kernel_size, stride, padding, bias=bias)\n",
        "\n",
        "            setattr(model, name, new_conv)\n",
        "        elif len(list(module.children())) > 0:\n",
        "            replace_conv2d_with_dsconv_except_first(module)\n",
        "\n",
        "# downsample 레이어 제외\n",
        "def replace_conv2d_with_dsconv_except_downsample(model):\n",
        "    for name, module in model.named_children():\n",
        "        if isinstance(module, nn.Conv2d):\n",
        "\n",
        "            if module.kernel_size == (1,1):\n",
        "                continue\n",
        "\n",
        "            # Replace Conv2d with DepthwiseSeparableConv\n",
        "            # Need to get the correct parameters from the original Conv2d layer\n",
        "            in_channels = module.in_channels\n",
        "            out_channels = module.out_channels\n",
        "            kernel_size = module.kernel_size\n",
        "            stride = module.stride\n",
        "            padding = module.padding\n",
        "            bias = module.bias is not None\n",
        "\n",
        "            new_conv = DepthwiseSeparableConv(in_channels, out_channels, kernel_size, stride, padding, bias=bias)\n",
        "\n",
        "            setattr(model, name, new_conv)\n",
        "        elif len(list(module.children())) > 0:\n",
        "            replace_conv2d_with_dsconv_except_downsample(module)\n",
        "\n",
        "# 첫 레이어와 downsample layer 제외\n",
        "def replace_conv2d_with_dsconv_except_first_and_downsample(model):\n",
        "    for name, module in model.named_children():\n",
        "        if isinstance(module, nn.Conv2d):\n",
        "            if module.kernel_size != (3,3) :\n",
        "                continue\n",
        "\n",
        "            in_channels = module.in_channels\n",
        "            out_channels = module.out_channels\n",
        "            kernel_size = module.kernel_size\n",
        "            stride = module.stride\n",
        "            padding = module.padding\n",
        "            bias = module.bias is not None\n",
        "\n",
        "            new_conv = DepthwiseSeparableConv(in_channels, out_channels, kernel_size, stride, padding, bias=bias)\n",
        "\n",
        "            setattr(model, name, new_conv)\n",
        "        elif len(list(module.children())) > 0:\n",
        "            replace_conv2d_with_dsconv_except_first_and_downsample(module)"
      ],
      "metadata": {
        "id": "QcE5U9fvUmne"
      },
      "id": "QcE5U9fvUmne",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "0: replace_conv2d_with_dsconv: 모든 Conv2d 레이어를 depthwise separable conv2d로 변경\n",
        "\n",
        "1: replace_conv2d_with_dsconv_except_first:첫 레이어만 제외하고 변경  \n",
        "(깃헙 문서에 따르면 이렇게 하는게 성능이 좋다고 하네요..)\n",
        "\n",
        "2: replace_conv2d_with_dsconv_except_first_and_downsample: 첫 레이어와 다운샘플링 레이어를 제외    "
      ],
      "metadata": {
        "id": "W6amSwVH4Gfv"
      },
      "id": "W6amSwVH4Gfv"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "932efb74",
      "metadata": {
        "id": "932efb74"
      },
      "outputs": [],
      "source": [
        "replace_conv2d = [replace_conv2d_with_dsconv, replace_conv2d_with_dsconv_except_first, replace_conv2d_with_dsconv_except_first_and_downsample]\n",
        "\n",
        "model_ft = initialize_model(model_name, num_classes, feature_extract=feature_extract, use_pretrained=pretrained)\n",
        "replace_conv2d[1](model_ft)\n",
        "model_ft = model_ft.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d94dd91",
      "metadata": {
        "collapsed": true,
        "id": "0d94dd91"
      },
      "outputs": [],
      "source": [
        "params_to_update = model_ft.parameters()\n",
        "print(\"Params to learn:\")\n",
        "if feature_extract:\n",
        "    params_to_update = []\n",
        "    for name, param in model_ft.named_parameters():\n",
        "        if param.requires_grad == True:\n",
        "            params_to_update.append(param)\n",
        "            #print(\"\\t\",name)\n",
        "else:\n",
        "    for name,param in model_ft.named_parameters():\n",
        "        if param.requires_grad == True:\n",
        "            pass\n",
        "            print(\"\\t\",name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4090abc7",
      "metadata": {
        "id": "4090abc7"
      },
      "outputs": [],
      "source": [
        "#base_lr = 0.0012\n",
        "#max_lr = 0.0022\n",
        "#num_epoch = 30\n",
        "\n",
        "cost = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer_ft = optim.SGD(params_to_update, lr=lr, momentum=momentum, nesterov = True)\n",
        "#step_size = 2 * math.ceil( len(dataloaders_dict['train']) / batch_size )\n",
        "#scheduler = optim.lr_scheduler.CyclicLR(optimizer_ft, base_lr = base_lr, max_lr = max_lr, step_size_up=step_size, mode='exp_range', gamma=0.994, scale_mode='cycle', cycle_momentum=True, base_momentum=0.8, max_momentum=0.9, last_epoch=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2e99fb14",
      "metadata": {
        "id": "2e99fb14"
      },
      "outputs": [],
      "source": [
        "val_loss = []\n",
        "val_acc = []\n",
        "train_loss = []\n",
        "train_acc = []\n",
        "best_acc = .0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc013347",
      "metadata": {
        "id": "cc013347"
      },
      "outputs": [],
      "source": [
        "#모델 훈련\n",
        "\n",
        "es = EarlyStopping(patience = 3, verbose = True, delta = 0.005)\n",
        "\n",
        "#total_epochs = cfg.training.epochs\n",
        "\n",
        "model_ft, hist_val, hist_train, time_elapsed, best_acc = train_model(\n",
        "    model_ft,\n",
        "    dataloaders_dict,\n",
        "    cost,\n",
        "    optimizer_ft,\n",
        "    save_best_weights_path,\n",
        "    save_last_weights_path,\n",
        "    num_epochs,\n",
        "    early_stopping = es,\n",
        "    is_inception=(model_name == \"inception\")\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5c41da2e",
      "metadata": {
        "id": "5c41da2e"
      },
      "source": [
        "# 학습 결과 및 모델 분석"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델 분석\n",
        "https://github.com/MrYxJ/calculate-flops.pytorch\n",
        "\n",
        "모델의 FLOPs, MACs, params 계산\n",
        "라이브러리 설치시 환경을 많이 바꾸는거 같아서 일단 주석처리 해둡니다.  \n",
        "\n",
        "로컬에서는 돌리지 마세요.\n"
      ],
      "metadata": {
        "id": "PfOlK5bSQkr_"
      },
      "id": "PfOlK5bSQkr_"
    },
    {
      "cell_type": "code",
      "source": [
        "# FLOPs 분석을 위한 라이브러리\n",
        "# !pip install calflops\n",
        "# from calflops import calculate_flops\n",
        "\n",
        "# model = models.resnet18()\n",
        "# batch_size = batch_size\n",
        "# input_shape = (batch_size, 3, 224, 224)\n",
        "# flops, macs, params = calculate_flops(model=model,\n",
        "#                                       input_shape=input_shape,\n",
        "#                                       output_as_string=True,\n",
        "#                                       output_precision=4,\n",
        "#                                       print_detailed=False)\n",
        "# print(\"ResNet18 FLOPs:%s   MACs:%s   Params:%s \\n\" %(flops, macs, params))"
      ],
      "metadata": {
        "id": "oCKCp4HMQym5"
      },
      "id": "oCKCp4HMQym5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model = model_ft\n",
        "# batch_size = batch_size\n",
        "# input_shape = (batch_size, 3, 224, 224)\n",
        "# flops, macs, params = calculate_flops(model=model,\n",
        "#                                       input_shape=input_shape,\n",
        "#                                       output_as_string=True,\n",
        "#                                       output_precision=4,\n",
        "#                                       print_detailed=False)\n",
        "# print(\"ResNet18 with depsep conv FLOPs:%s   MACs:%s   Params:%s \\n\" %(flops, macs, params))"
      ],
      "metadata": {
        "id": "YGthLXI3RdcS"
      },
      "id": "YGthLXI3RdcS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "f98b585c",
      "metadata": {
        "id": "f98b585c"
      },
      "source": [
        "## 학습 결과 시각화 함수 선언"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "45e811fb",
      "metadata": {
        "id": "45e811fb"
      },
      "outputs": [],
      "source": [
        "# train/valid 학습 결과 loss/acc 분류\n",
        "val_loss = hist_val['loss']\n",
        "val_acc = hist_val['acc']\n",
        "train_loss = hist_train['loss']\n",
        "train_acc = hist_train['acc']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "14223b3b",
      "metadata": {
        "id": "14223b3b"
      },
      "outputs": [],
      "source": [
        "def visualization(train, val, is_loss = True):\n",
        "  if is_loss:\n",
        "    plt.figure(figsize=(9,5))\n",
        "    plt.plot(torch.tensor(train, device =  'cpu'), label = 'Training loss')\n",
        "    plt.plot(torch.tensor(val, device =  'cpu'), label = 'Val loss')\n",
        "    plt.title('Training and validation loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "  else:\n",
        "    plt.figure(figsize=(9,5))\n",
        "    plt.plot(torch.tensor(train, device =  'cpu'), label = 'Training acc')\n",
        "    plt.plot(torch.tensor(val, device =  'cpu'), label = 'Val acc')\n",
        "    plt.title('Training and validation acc')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Acc')\n",
        "    plt.legend()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "50121eda",
      "metadata": {
        "id": "50121eda"
      },
      "source": [
        "## confusion_matrix for val data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb5ac678",
      "metadata": {
        "id": "eb5ac678"
      },
      "outputs": [],
      "source": [
        "def predict(model, test_loader):\n",
        "\n",
        "    with torch.no_grad():\n",
        "        logits = []\n",
        "\n",
        "        for inputs in test_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            model.eval()\n",
        "            outputs = model(inputs).cpu()\n",
        "            logits.append(outputs)\n",
        "\n",
        "    probs = nn.functional.softmax(torch.cat(logits), dim=1).numpy()\n",
        "    return probs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ffc10362",
      "metadata": {
        "id": "ffc10362"
      },
      "outputs": [],
      "source": [
        "def confusion_matrix():\n",
        "    # 실제 label 추출\n",
        "    actual = [image_datasets['val'][i][1] for i in range(len(image_datasets['val']) ) ]\n",
        "\n",
        "    # 이미지 추출\n",
        "    image = [image_datasets['val'][i][0] for i in range( len(image_datasets['val']) ) ]\n",
        "\n",
        "    img_conf_dataloader = torch.utils.data.DataLoader(image, batch_size=cfg.data.batch_size, shuffle=False, num_workers=0)\n",
        "\n",
        "    #image_conf_dataloader의 이미지들의 확률 생성\n",
        "    probs = predict(model_ft, img_conf_dataloader)\n",
        "    #가장 높은 확률의 결과로 배열 생성\n",
        "    preds = np.argmax(probs, axis=1)\n",
        "\n",
        "    # 테이블 생성\n",
        "    df = pd.DataFrame({'actual': actual, 'preds': preds})\n",
        "\n",
        "    confusion_matrix = pd.crosstab(df['actual'], df['preds'], rownames=['Actual'], colnames=['Predicted'], margins = False)\n",
        "\n",
        "    # 인코더 다운로드\n",
        "    label_encoder = pickle.load(open(\"label_encoder.pkl\", 'rb'))\n",
        "\n",
        "    # 클래스 목록 가져오기기\n",
        "    yticklabels = label_encoder.classes_\n",
        "\n",
        "    plt.subplots(figsize=(20,20))\n",
        "\n",
        "    # confusion matrix가 제대로 출력되지 않는 부분을 수정했습니다.\n",
        "    sn.heatmap(confusion_matrix, annot=True, fmt=\"d\", linewidths=0.5, cmap=\"YlGnBu\", cbar=False, vmax = 30, yticklabels = yticklabels, xticklabels = label_encoder.classes_[np.unique(preds)])\n",
        "    #sn.heatmap(confusion_matrix, annot=True, fmt=\"d\", linewidths=0.5, cmap=\"YlGnBu\", cbar=False, vmax = 30, yticklabels = yticklabels, xticklabels = yticklabels);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af3b44cb",
      "metadata": {
        "id": "af3b44cb"
      },
      "outputs": [],
      "source": [
        "confusion_matrix()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bec01dbe",
      "metadata": {
        "id": "bec01dbe"
      },
      "source": [
        "## lr_cycle, acc, loss 시각화"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fcda28cd",
      "metadata": {
        "id": "fcda28cd"
      },
      "outputs": [],
      "source": [
        "#plt.figure(figsize=(17,10))\n",
        "#plt.plot(lr_cycle);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f92c643a",
      "metadata": {
        "id": "f92c643a"
      },
      "outputs": [],
      "source": [
        "visualization(train_acc, val_acc, is_loss = False)\n",
        "print('\\n')\n",
        "visualization(train_loss, val_loss, is_loss = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "af69da2b",
      "metadata": {
        "id": "af69da2b"
      },
      "source": [
        "# 모델 테스트"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e374046",
      "metadata": {
        "id": "2e374046"
      },
      "source": [
        "## 샘플 테스트"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d81d0b49",
      "metadata": {
        "id": "d81d0b49"
      },
      "outputs": [],
      "source": [
        "def predict_one_sample(model, img_tensor, device=device):\n",
        "    with torch.no_grad():\n",
        "        img_tensor = img_tensor.to(device)\n",
        "        model.eval()\n",
        "        y_hat = model(img_tensor).cpu()\n",
        "        y_pred = torch.nn.functional.softmax(y_hat, dim=1).numpy()\n",
        "    return y_pred"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "582ee44d",
      "metadata": {
        "id": "582ee44d"
      },
      "source": [
        "## 테스트 샘플 시각화"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f263b50",
      "metadata": {
        "id": "7f263b50"
      },
      "outputs": [],
      "source": [
        "import matplotlib.patches as patches\n",
        "from matplotlib.font_manager import FontProperties\n",
        "\n",
        "fig, ax = plt.subplots(nrows=3, ncols=3, figsize=(12, 12), \\\n",
        "                        sharey=True, sharex=True)\n",
        "\n",
        "label_encoder = pickle.load(open(\"label_encoder.pkl\", 'rb'))\n",
        "\n",
        "for fig_x in ax.flatten():\n",
        "    random_characters = int(np.random.uniform(0, 1000))\n",
        "    im_val, label = image_datasets['val'][random_characters]\n",
        "    img_label = \" \".join(map(lambda x: x.capitalize(),\\\n",
        "                image_datasets['val'].label_encoder.inverse_transform([label])[0].split('_')))\n",
        "\n",
        "    imshow(im_val.data.cpu(), \\\n",
        "          title=img_label, plt_ax=fig_x)\n",
        "\n",
        "    actual_text = \"Actual : {}\".format(img_label)\n",
        "\n",
        "    fig_x.add_patch(patches.Rectangle((1, 189), 120, 35, color='white'))\n",
        "    font0 = FontProperties()\n",
        "    font = font0.copy()\n",
        "    prob_pred = predict_one_sample(model_ft, im_val.unsqueeze(0))\n",
        "    predicted_proba = np.max(prob_pred)*100\n",
        "    y_pred = np.argmax(prob_pred)\n",
        "\n",
        "    predicted_label = label_encoder.classes_[y_pred]\n",
        "    predicted_text = \"{} :\\n {:.0f}%\".format(predicted_label,predicted_proba)\n",
        "\n",
        "    fig_x.text(1, 189, predicted_text , horizontalalignment='left', fontproperties=font,\n",
        "                    verticalalignment='top',fontsize=8, color='black',fontweight='bold')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a710a36d",
      "metadata": {
        "collapsed": true,
        "id": "a710a36d"
      },
      "outputs": [],
      "source": [
        "probs = predict(model_ft, dataloader_test)\n",
        "\n",
        "label_encoder = pickle.load(open(\"label_encoder.pkl\", 'rb'))\n",
        "\n",
        "preds = label_encoder.inverse_transform(np.argmax(probs, axis = 1 ))\n",
        "test_file_names = [path.name for path in image_datasets_test.files_path]\n",
        "\n",
        "for i in range(len(test_file_names)):\n",
        "  test_file_names[i] = test_file_names[i].split('.')[0].rsplit('_', 1)[0]\n",
        "\n",
        "present_labels = np.unique(test_file_names)\n",
        "\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(test_file_names, preds, labels=present_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "506a8c11",
      "metadata": {
        "id": "506a8c11"
      },
      "outputs": [],
      "source": [
        "#my_submit = pd.DataFrame({'Id': test_filenames, 'Expected': preds})\n",
        "#my_submit.head()\n",
        "#my_submit.to_csv('simspsons.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "colab": {
      "provenance": [],
      "gpuType": "L4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}